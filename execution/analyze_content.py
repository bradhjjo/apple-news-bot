#!/usr/bin/env python3
"""
ì½˜í…ì¸  ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸
Directive: directives/analyze_content.md
"""

import json
import os
from datetime import datetime
from typing import List, Dict
from textblob import TextBlob
from collections import Counter
import re

def load_data():
    """ìˆ˜ì§‘ëœ ë°ì´í„° ë¡œë“œ"""
    data = {}
    
    # ë‰´ìŠ¤ ë°ì´í„°
    news_file = '.tmp/news_articles.json'
    if os.path.exists(news_file):
        with open(news_file, 'r', encoding='utf-8') as f:
            data['news'] = json.load(f)
    else:
        data['news'] = []
    
    # ì†Œì…œ ë¯¸ë””ì–´ ë°ì´í„°
    social_file = '.tmp/social_posts.json'
    if os.path.exists(social_file):
        with open(social_file, 'r', encoding='utf-8') as f:
            data['social'] = json.load(f)
    else:
        data['social'] = []
    
    # ì£¼ê°€ ë°ì´í„°
    stock_file = '.tmp/stock_data.json'
    if os.path.exists(stock_file):
        with open(stock_file, 'r', encoding='utf-8') as f:
            data['stock'] = json.load(f)
    else:
        data['stock'] = None
    
    return data

def analyze_sentiment(text: str) -> tuple:
    """í…ìŠ¤íŠ¸ ê°ì„± ë¶„ì„ (TextBlob ì‚¬ìš©)"""
    try:
        blob = TextBlob(text)
        polarity = blob.sentiment.polarity  # -1 (ë¶€ì •) ~ 1 (ê¸ì •)
        
        if polarity > 0.1:
            sentiment = "ê¸ì •ì "
        elif polarity < -0.1:
            sentiment = "ë¶€ì •ì "
        else:
            sentiment = "ì¤‘ë¦½"
        
        return sentiment, polarity
    except:
        return "ì¤‘ë¦½", 0.0

def analyze_content(data: dict) -> dict:
    """ì „ì²´ ì½˜í…ì¸  ë¶„ì„"""
    print("ğŸ” Analyzing content...")
    
    # ê°ì„± ë¶„ì„
    sentiments = {'ê¸ì •ì ': 0, 'ì¤‘ë¦½': 0, 'ë¶€ì •ì ': 0}
    sentiment_scores = []
    
    # ë‰´ìŠ¤ ë¶„ì„
    analyzed_news = []
    for article in data['news'][:10]:  # ìƒìœ„ 10ê°œ
        text = f"{article['title']} {article.get('summary', '')}"
        sentiment, score = analyze_sentiment(text)
        
        sentiments[sentiment] += 1
        sentiment_scores.append(score)
        
        analyzed_news.append({
            'title': article['title'],
            'source': article['source'],
            'url': article['url'],
            'sentiment': sentiment,
            'score': round(score, 2)
        })
    
    # ì†Œì…œ ë¯¸ë””ì–´ ë¶„ì„
    analyzed_social = []
    for post in data['social'][:10]:  # ìƒìœ„ 10ê°œ
        text = f"{post['title']} {post.get('text', '')}"
        sentiment, score = analyze_sentiment(text)
        
        sentiments[sentiment] += 1
        sentiment_scores.append(score)
        
        analyzed_social.append({
            'title': post['title'],
            'platform': post['platform'],
            'url': post['url'],
            'score': post['score'],
            'sentiment': sentiment
        })
    
    # ì „ì²´ ê°ì„± ì ìˆ˜
    overall_score = sum(sentiment_scores) / len(sentiment_scores) if sentiment_scores else 0
    
    if overall_score > 0.1:
        overall_sentiment = "ê¸ì •ì "
    elif overall_score < -0.1:
        overall_sentiment = "ë¶€ì •ì "
    else:
        overall_sentiment = "ì¤‘ë¦½"
    
    # í‚¤ì›Œë“œ ì¶”ì¶œ
    all_text = ' '.join([a['title'] for a in data['news']] + [p['title'] for p in data['social']])
    keywords = extract_keywords(all_text)
    
    # ìš”ì•½ ìƒì„±
    summary = generate_summary(analyzed_news, analyzed_social, overall_sentiment)
    
    # ê²°ê³¼ êµ¬ì„±
    report = {
        'date': datetime.now().strftime('%Y-%m-%d'),
        'stock': data['stock'] if data['stock'] else {
            'price': 0,
            'change_percent': 0,
            'trend': 'ë°ì´í„° ì—†ìŒ'
        },
        'sentiment': {
            'overall': overall_sentiment,
            'score': round(overall_score, 2),
            'positive_count': sentiments['ê¸ì •ì '],
            'neutral_count': sentiments['ì¤‘ë¦½'],
            'negative_count': sentiments['ë¶€ì •ì ']
        },
        'top_news': analyzed_news[:5],
        'top_social': analyzed_social[:5],
        'keywords': keywords[:10],
        'summary': summary
    }
    
    print(f"âœ“ Sentiment: {overall_sentiment} ({overall_score:.2f})")
    print(f"âœ“ Top keywords: {', '.join(keywords[:5])}")
    
    return report

def extract_keywords(text: str) -> List[str]:
    """í‚¤ì›Œë“œ ì¶”ì¶œ (ë¹ˆë„ ê¸°ë°˜)"""
    # ì†Œë¬¸ì ë³€í™˜ ë° ë‹¨ì–´ ì¶”ì¶œ
    words = re.findall(r'\b[a-zA-Z]{3,}\b', text.lower())
    
    # ë¶ˆìš©ì–´ ì œê±°
    stopwords = {'the', 'and', 'for', 'with', 'this', 'that', 'from', 'are', 'was', 'has', 'have', 'will', 'can', 'but', 'not', 'you', 'all', 'new', 'more', 'get', 'how', 'out', 'now', 'may'}
    filtered_words = [w for w in words if w not in stopwords and len(w) > 3]
    
    # ë¹ˆë„ ê³„ì‚°
    word_freq = Counter(filtered_words)
    
    # ìƒìœ„ í‚¤ì›Œë“œ ë°˜í™˜
    return [word.capitalize() for word, count in word_freq.most_common(15)]

def generate_summary(news: List[Dict], social: List[Dict], sentiment: str) -> str:
    """ì „ì²´ ìš”ì•½ ìƒì„±"""
    summary_parts = []
    
    # ë‰´ìŠ¤ ìš”ì•½
    if news:
        top_news_titles = [n['title'][:60] + '...' if len(n['title']) > 60 else n['title'] for n in news[:3]]
        summary_parts.append(f"ì£¼ìš” ë‰´ìŠ¤: {', '.join(top_news_titles)}")
    
    # ê°ì„± ìš”ì•½
    summary_parts.append(f"ì „ì²´ì ìœ¼ë¡œ {sentiment} ë¶„ìœ„ê¸°ì…ë‹ˆë‹¤.")
    
    # ì†Œì…œ ë¯¸ë””ì–´ ìš”ì•½
    if social:
        summary_parts.append(f"ì†Œì…œ ë¯¸ë””ì–´ì—ì„œ {len(social)}ê°œì˜ ê´€ë ¨ í† ë¡ ì´ í™œë°œí•©ë‹ˆë‹¤.")
    
    return ' '.join(summary_parts)

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ“Š Starting content analysis...")
    
    # ë°ì´í„° ë¡œë“œ
    data = load_data()
    
    if not data['news'] and not data['social']:
        print("âŒ No data to analyze")
        return False
    
    print(f"âœ“ Loaded {len(data['news'])} news articles")
    print(f"âœ“ Loaded {len(data['social'])} social posts")
    
    # ì½˜í…ì¸  ë¶„ì„
    report = analyze_content(data)
    
    # ê²°ê³¼ ì €ì¥
    output_dir = '.tmp'
    os.makedirs(output_dir, exist_ok=True)
    output_file = os.path.join(output_dir, 'daily_report.json')
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… Saved analysis report to {output_file}")
    
    return True

if __name__ == '__main__':
    success = main()
    exit(0 if success else 1)
